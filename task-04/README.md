# Large Language Model (Gemma 1.5 flash)

##  **About Gemma 1.5 flash:**

- **LLM:** Understands and generates human-quality text.
- **Generative:** Creates articles, code, emails, etc.
- **Knowledge Base:** Accesses real-world information.
- **Code Generation:** Writes various programming languages.
- **Problem-Solving:** Assists with tasks like summarization and translation.
- **Question Answering:** Provides comprehensive answers.
- **Text Generation:** Generates creative content like poems or code.


## Installation

- Make sure you have Python installed. If not, you can download and install it from Python's official website.

- Create a Virtualenv .
  ```bash
   python -m venv .venv
  ```
- Activate the Virtualenv.
  ```bash
   source .venv/bin/activate
  ```
- Install Necessary packages.
  ```bash
   pip install -r 'requirements.txt'
  ```

### The command used to run the streamlit python file 
```streamlit run gemma.py```

### Struggles faced
- I have knowledge in  API management
- finding the model and i don't know where to start
- i Refered some youtube videos for that one.
- Streamlit has amazing feature that we can convert the code into app in a miniute
 